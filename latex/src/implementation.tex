\section{Parameters Choice}
The parameters choice, especially when it comes to the distribution parameters of the noise distribution, is essential to avoid some simple, yet potentially catastrophic attacks. Although the parameters choice is simpler than in the setting of the RLWE, as it is evident from the quite sizable section of attacks on specific rings in \cite{RLWE_attacks}, some care needs to be taken.\\
The authors of Frodo present four possible parameter choices. All of these choices have some points in common. First of all, in order to equally share the bandwidth between the actors of the protocol, $\bar{m}$ and $\bar{n}$ are chosen to be equal. Moreover, they are fixed to $8$ for all choices of parameters, using the parameter $n$ and the bitrate $B$ to generate keys of the desired length. Moreover, the distributions are approximations of 
The first two are respectively a toy set of parameters, and one giving an acceptable level of security only against classic attackers, so they will not be examined in this section. The third and fourth set of parameters are aimed to provide an acceptable level of security against quantum attackers.\\
First, let's examine the recommended parameters. These parameters claim to provide 128 bit  security against quantum adversaries. The lattice dimension $n$ is $752$, with the modulus $q=2^{15}$. In order to keep $\bar{n}=8$, while still producing a $256$ bit key, the bitrate must be $B=256/\bar{n}^2=4$. Finally, the CDF for the inverse sampling is $\mathbf{T}=(1206, 919, 406, 104, 15, 1)$, requiring $12$ bits of entropy for each sample. This distribution binds the sampled coefficients to be in the range $\{-5,\ldots,+5\}$.\\
The paranoid parameters, on the other hand, claim to provide 128 bit security even with the most pessimistic assumptions on the effectiveness of known attacks. The lattice dimension $n$ is $864$, with the same modulus $q=2^{15}$, and bitrate $B=4$. The CDF for the inverse sampling is chosen to be closer to a Gaussian distribution as $\mathbf{T}=(19304, 14700, 6490, 1659, 245, 21, 1)$, which requires $16$ bits of entropy for each sample. This distribution binds the sampled coefficients to be in the range $\{-6,\ldots,6\}$.
It is worth mentioning that the claimed security levels for the recommended and paranoid parameters are actually lower than what can be achieved with existing attacks. A more realistic security level can be computed using \cite{parameters}, a useful tool to estimate the level of security of a given instance of the LWE problem, given the known attacks. Running the tool on the recommended and paranoid parameters, reveals that the most effective attack is currently the uSVP attack, as revised in \cite{RUSVP}, and the parameters yield an actual level of security of, respectively, 173 and 199.8 bit. The reason for the lower claimed security level of 128 bit, is due to the pessimistic assumptions made on the attacker capabilities.

\section{Implementation Rationale}
As the main goal of this thesis is not to examine the differences of Frodo and New Hope only from a theoretical point of view, but also to give a practical comparison of the two, an original implementation is presented. It focuses on portability, low memory usage, both in terms of executable size and execution memory and It uses stack memory in all its internal functions, naturally avoiding issues related to memory handling, so frequent in a language like C.\\
The nature of the LWE primitives naturally suits a constant time implementation for the key generation and reconciliation primitives, and with a little more effort all the critical parts of the protocol can be made completely branchless, with only a few loops, which only depend on public parameters and not on execution data, neither private nor public. Thanks to this peculiarities of Frodo, most of the necessary validity checks can be performed at compile time, using asserts in the configuration header, thus saving additional time and complexity at run time.\\
Last but not least, the implementation only uses well defined language primitives, with the only exception of the structures used for the entropy handling in the distribution inverse sampling\footnote{More on this in Section \ref{sec:imp:dist}} which might produce different results depending on the underlying hardware. This choice allows all critical parts of the implementation to be compiled on virtually any system, remaining consistent. Moreover, this could enable a porting of the implementation using automatic tools, potentially requiring some minor tweaking for the entropy handling. In order to enforce this, the code is compiled with the strictest possible set of flags, treating all warning as errors and prohibiting undefined behaviors.\\
With this in mind, the proposed implementation focuses on streamlining the one proposed by the authors of \cite{frodo}, pruning unnecessary branches and options that are a burden during execution and make the code less readable.\\
Let's examine in detail the different aspects of the protocol implementation.

\subsection{Element representation}
The core choice we need to make when implementing Frodo is element representation, which can either be tight or redundant. A tight representation would save memory, but it would burden the implementation with the modular arithmetic handling. On the other hand, a redundant representation would ease this burden, either by using lazy reduction, or by carefully selecting modulo and bits so that overflows can be exploited to automatically take care of modular arithmetic. This comes at the cost of an increased memory usage.\\
The authors of \cite{frodo} have no doubts on their choice, and their intents are quite clear from the parameters choice. They don't even consider using lazy reduction and force the modulus to be a power of two, thus enabling the implementation to ignore the modular arithmetic. Indeed, considering that the highest possible modulus in any parameter choice is $2^{15}$, an element of a matrix can always be represented as an integer in $\mathbb{Z}_{16}$. This means that an element can always fit an unsigned $16$ bit unsigned integer, regardless of the parameter choice, and that the modular arithmetic is taken car of by integer overflow. It is worth pointing out that unsigned integer overflow is well defined in the C standard.\\
The final advantage of this representation comes when an element needs to be reduced to fit in $\mathbb{Z}_n$: a single AND instruction with the mask $2^{n}-1$ is enough to compute the desired value. This final computation might not even be necessary, as it is often the case that either specific bits are extracted from the 16 bits integer itself, or that the integers are packed into byte arrays for transmission. In these cases, it is possible to perform the bitwise operations needed to achieve the final goal, in such a way that the modular arithmetic is automatically handled.\\

\subsection{Random Distributions}\label{sec:imp:dist}
The inverse sampling procedure used to generate both the secrets and the noise matrices consists of two main parts: entropy gathering and the inverse sampling itself.\\
The entropy gathering is the only part where possibly undefined operations are performed in the whole implementation. A packed structure, specific for the necessary bits of entropy required, is filled with random bytes. Then, the packed fields are called to retrieve the desired bits, without having to resort to complex bitwise operations. The problem with packed structures is that different compilers might place the packed fields in a different order inside of the packed struct. Although this seems to break the claim of portability made in the rationale, the packed structs are only used to access the randomly sampled bits, for which the order of access in not actually important. Since the total amount of memory taken by the packed struct is guaranteed to be the same under any compliant compiler, it holds that all and only the randomly sampled bits are accessed, thus producing the required amount of random bits in the end.\\
Once the entropy gathering is settled, the second part, i.e. the inverse sampling, can take place. This procedure can be further broken down into the lookup of the CDF array and the restoration of the sign. The inverse lookup can be performed in a branchless fashion by iterating over the CDF array and using a constant time comparison of the generated entropy bits with the elements in the array, increasing the sample of the result of said comparison. Such comparison, as well as the sign restoring procedure, can be performed with a few bitwise operations, exploiting the representation of the elements as 16 bit unsigned integers.\\
The inverse lookup is described in Algorithm \ref{alg:imp:i_lookup}. The constant time comparison works because both the elements of CDF and the bits are lower than $2^{15}$. Consider $v\in$CDF and $b$, the only way for the most significant bit of $v-b$ to be one is for $b$ to be greater of $v$, which causes their difference to underflow.\\
\begin{b_algorithm}{Branchless inverse lookup}
{$b$, the bits of entropy}
{$s$, the generated sample}
{alg:imp:i_lookup}
\STATE $s\gets 0$
\FOR{$i \gets 0$ \TO $len(CDF)-1$}
\STATE $s \gets s + (CDF[i]-b)\gg15$
\ENDFOR
\RETURN $s$
\end{b_algorithm}
The sign restoring is a bit trickier. It exploits the fact that if the elements are represented as $16$ bit unsigned integers, $-x=1+~x=1+(\text{0xFFFF})=1+(x\oplus(-1))$. On the other hand,$x=0+(x\oplus0)$. Combining these two equations, the branchless conditional sign flip can be formulated as $b+(x\oplus(-b))$, where $b$ is the sign bit.\\
This is the inverse sampling for one sample, but in Frodo it is usually needed to sample a matrix using the inverse sample. The authors of Frodo implement this matrix sampling by gathering all the entropy required in an array, and then access it while performing the inverse sampling. This procedure requires almost double the memory required for the sampled matrix alone for Frodo Recommended, and exactly double the memory for Frodo Paranoid\footnote{About 13 kbytes of additional memory.}. It would be possible to generate the entropy on the fly, but this negatively affects the performance of the implementation. Nevertheless, there is a way to generate the entropy in bulk without increasing the memory usage. Since the entropy required to generate a sample is lower or equal than two bytes, it is possible to temporarily store the generated entropy in the buffer used to store the samples. This operation requires a little care in the order of samples generation so that the entropy is not accidentally overwritten, but the benefits are well worth it.

\subsection{Parameter Generation}
The parameter generation, alongside key pairs generation, is the most burdensome part of Frodo. Although, not much can be added to the considerations made in Section \ref{sec:fr:a_generation} about the generation of the parameter, either in full, or by row or column.\\
The different possibilities to generate the parameter $a$ offer various trade-offs between memory usage and speed. The fastest way\footnote{Assuming the cost of generating the parameter is amortized by reusing it.} to generate the parameter and the keys is to generate the whole parameter, as long as the operations are constructed in such a way that caching is effective. Then, it is possible to generate the entropy one row, or eight columns at a time. These procedures are slower than the simple multiplication with the parameter, but faster than the combined cost of the parameter and key generation, let alone their lower memory cost of $O(n)$ and $O(\bar{n}n)$ respectively. It is also possible to to give an alternative procedure to perform the multiplication of the parameter on the right while still generating the parameter one row at a time. This procedure is slower than the two aforementioned procedures, but it provides a way to further reduce the memory requirements of the multiplication on the right to $O(n)$. The last procedure consists in generating the parameter one stripe at a time, achieving a constant memory implementation. On the other hand, this procedure is significantly slower than the others and it is recommended only when the memory requirements are really tight. Indeed, it is worth pointing out that although the parameter generation is constant memory with the last method, the memory required for the whole protocol is still $O(\bar{n}n)$ because of the keys. This makes the last method useful only if every byte counts, while the two methods to generate the parameter one row at a time offer the best compromise for general use cases.\\
Finally, it is worth mentioning that while key generation needs to be handled with care to mitigate side channel attacks, the generation of the public parameter is not so critical. There is no advantage in loosening the requirements on constant timeness, but there are small gains from avoiding some of the final cleanups of the memory used in some parts of the procedure. For instance, the buffers used in the AES encryption of the parameter stripes can be safely left alone.\\


\subsection{Matrix Multiplication}\label{sec:imp:mult}
The shares recombination and the public key computation are nothing more than matrix multiplication, with the addition of the sampled noise matrices. Unfortunately, the dimension of the matrices used in Frodo is not high enough to justify more advanced methods of matrix multiplication, and the naive algorithm is the preferred choice. Still, the approach followed by the authors of Frodo for theses procedures can be improved. Let's examine how the original implementation behaves.\\
The typical operation that needs to be executed when multiplying two matrices in Frodo, is not just a simple multiplication, but it also requires the addition of a sampled noise matrix, i.e. $ab + e$. In the original implementation, all the three matrices $a$, $b$, and $e$ are allocated, plus the destination matrix. Then, the matrix e is copied into the destination matrix, and the product is computed and stored directly in the destination matrix.\\
It is easy to see that one of these allocations is unnecessary: the matrix $e$ is allocated, used to store the samples and then copied over to the destination. So, why not making the matrix $e$ itself the destination matrix. This approach saves the allocation of a matrix, which is quite burdensome, and also the time necessary to copy over the matrix e to the destination. Since the error matrices are generated on the fly and never reused, nothing is lost by destroying $e$, and it can save up to one third of the necessary memory, in the case of the multiplication with the parameter generated by rows. Even if the product does not require the addition of noise, there is no extra cost in zeroing the matrix before passing it to the multiplication utility, w.r.t zeroing out the matrix as we go during the product.\\
Finally, one more consideration is critical when implementing the matrix product. For efficiency reasons it is crucial to exploit the processor cache as much as possible. Since the matrices in Frodo are stored in a row-major order\footnote{This means that they are actually 1-dimensional arrays, which in turn means that the memory of a columns is not adjacent.}, operations cycling first over rows and then over columns are bound to be faster than operations cycling over columns first. Given this considerable performance boost it is worth trying to transform column major operations in row major operations when reasonable. The strategy adopted by the authors of \cite{frodo} to achieve this transformation is to compute the transpose matrix and successively working on that. Although this strategy yields a remarkable speed boost, it also requires to allocate an entire new matrix to store the transpose matrix. This is far from optimal. Indeed, it is enough to notice that only one row of the transpose matrix is cached at a time. Then, the same performance boost can be achieved by storing one column at a time. Using this strategy, only the column in use needs to be stored, achieving the same performance boost at a fraction of the memory required for storing the transpose matrix.

\subsection{Reconciliation}\label{sec:imp:rec}
The implementation proposed by the authors of \cite{frodo} for the reconciliation follows the definition quite closely. First, the elements of the recombined share are cross-rounded as described in Section \ref{sec:fr:rec}, with or without the help of the hint, depending on which party is executing the reconciliation. Then, the desired bits are extracted from the matrices and packed into the agreed key, using generic packing utilities\footnote{More on these utilities in the next section}.\\
Tailoring the packing function to this use case, or even better performing the packing on the fly, could allow some tricks that would not be otherwise possible. Indeed, knowing in advance the position and number of bits to pack, the key packing can be performed byte-wise, instead of bit-wise as in the original implementation, and in a branchless fashion, which is much better both from the standpoint of security and efficiency, since no logic is devoted to keep track of individual key bits and the position reached inside the key.\\
The proposed branchless reconciliation procedures, alongside the hint computation, are described in Algorithms \ref{alg:imp:hint}, \ref{alg:imp:rec}, \ref{alg:imp:rec_hint}. For simplicity, the $\bar{n}\times\bar{n}$ matrices are considered as $\bar{n}^2$ long arrays.

\begin{b_algorithm}{Hint computation}
{$m$, a $\bar{n}^2$ long array with the recombined shares}
{$h$, a $\bar{n}^2/8$ long array with the hint for reconciliation}
{alg:imp:hint}
\STATE $h\gets 0$
\FOR{$i \gets \bar{n}^2$ \TO $0 \textbf{ step }-8$}
\STATE $h[i/8] \ll 1$
\STATE $h[i/8] \gets h[i/8] | (m[i] \gg (\bar{B}-1) \& 1)$
\ENDFOR
\RETURN $h$
\end{b_algorithm}
\begin{b_algorithm}{Reconciliation}
{$m$, a $\bar{n}^2$ long array with the recombined shares}
{$k$, a $32$ long array with the reconciled key}
{alg:imp:rec}
\STATE $k\gets 0$
\STATE $c\gets8/B$
\STATE $rounder\gets1 \ll (\bar{B} - 1)$
\STATE $mask\gets(1 \ll B) - 1$
\FOR{$i \gets 0$ \TO $\bar{n}^2$}
\STATE $k[i/c] \ll B$
\STATE $k[i/c] \gets k[i/c] | ((m[i]+rounder) \gg \bar{B} \& mask)$
\ENDFOR
\RETURN $s$
\end{b_algorithm}
\begin{b_algorithm}{Reconciliation with hint}
{$m$, a $\bar{n}^2$ long array with the recombined shares, $h$, a $\bar{n}^2/8$ long array with the hint for reconciliation}
{$k$, a $32$ long array with the reconciled key}
{alg:imp:rec_hint}
\STATE $k\gets 0$
\STATE $c\gets8/B$
\STATE $hint\_rounder\gets 1 \ll (\bar{B} - 2)$
\STATE $rounder\gets 1 \ll (\bar{B} - 1)$
\STATE $mask=(1 \ll B) - 1$
\FOR{$i \gets 0$ \TO $\bar{n}^2$}
\STATE \texttt{/* Extract hint bit */}
\STATE $hint\_bit\gets  h[i/8] \gg (i\%8) \& 1$
\STATE \texttt{/* Check if hint is necessary*/}
\STATE $use\_hint\gets (m[i]\gg(\bar{B}-2) + 1) \gg 1 \& 1$
\STATE \texttt{/* Compute the bias provided from the hint, if any */}
\STATE $hint\_bias=use\_hint * (hint\_bit\ll1-1) * hint\_rounder$
\STATE \texttt{/* Use the bias to force rounding up or down */}
\STATE $k[i/c] \gets k[i/c] | ((m[i]+rounder+hint\_bias) \gg \bar{B} \& mask)$
\ENDFOR
\RETURN $s$
\end{b_algorithm}

\subsection{Bit Packing}
Although a redundant representation may be a good choice for internal element representation, it is not acceptable when the data has to be transmitted to the other party in the key exchange. This issue would add to the already hefty memory and bandwidth cost of Frodo. In order to address this problem, the elements in redundant representation are packed into the tight representation before transmission, and unpacked when received.\\
This part of the protocol is not really expensive, but there is much to improve in the original implementation. Indeed, the authors of \cite{frodo} try to fit the code for bit packing both to the element packing and the key packing from the reconciled combined shares. This overburdens the implementation with unnecessary complexity, forcing a packing algorithm that operates bit by bit, and ultimately resulting in fairly inefficient packing and unpacking procedures. Moreover, this choice might raise few eyebrows because it is used both for packing the public shares and the private reconciled secret. Decoupling the logic that handles private and public material allows for a simpler, branchless, implementation for the former, as seen in Section \ref{sec:imp:rec}, and a more efficient implementation for the latter, scratching the requirements for constant timeness and memory safety.\\
To address this issue, this implementation proposes a bytewise packing procedure. Unfortunately, the parameter choice does not allow for the most efficient branchless implementation, except for the Frodo Classic parameters. Nevertheless, all of the proposed moduli are greater than $2^8$, which means that the logic devoted to handling the cases where the number of bits in an element is less than a full byte is no longer necessary, allowing the aforementioned bytewise packing procedure. Still, some of the logic necessary to handle moduli that are not an even power of two, like $2^{11}$ for Frodo Toy, and $2^{15}$ for Frodo Recommended and Paranoid, need to be left in place, but the cost of this logic is just a fraction of the cost for the generic packing utility used by the authors of Frodo.

\section{Computational Complexity}
The computational complexity of Frodo is dominated by the parameter generation, with a cost of $O(n^2)$, and the public key generation, with a cost of $O(\bar{m}n^2)$ or $O(\bar{n}n^2)$. Luckily, we typically have $\bar{m},\bar{n} \ll n$, which means that the total cost of the algorithm can be summed up as $O(n^2)$. This cost does not look promising, but these parameters are typically very small, with $n$ being the largest, but still not large enough. Because of these small parameters, the computational cost of the protocol is remarkably small. Indeed, Frodo is just slightly slower than New Hope, and orders of magnitude faster than some the competitors PQKE, and even classical key exchanges, depending on the parameter choices.\\
The real hit to the performance of Frodo comes from the memory usage and the bandwith. Again, the culprits are the parameter generation and the matrix multiplications.\\
As far as memory is concerned, the naive implementation is still dominated by the memory necessary for the parameter $a$, which is $O(n^2)$, and the memory necessary for the private and public keys, which is $O(n)$\footnote{Considering, again, that $\bar{m},\bar{n} \ll n$}. In Section \ref{sec:fr:a_generation} there is an in-depth analysis of the cost, and the possible mitigations, for the generation of the parameter $a$, which practically reduces the memory requirements to $O(n)$.\\
Bandwidth is another weak spot of Frodo, as the matrices that need to be transmitted are not small either. As seen above, these grow as $O(n)$, which translates in a pretty hefty amount of data to be exchanged.\\

\section{Performance Summary}
In order to evaluate the performance of this implementation, it is benchmarked and compared to the implementation provided by the authors of \cite{frodo}. Tests and benchmarks have been carried out on a Dell XPS 13" 9360, with an Intel(R) Core(TM) i7-8550U CPU @ 1.80GHz, 16 GiB of LPDDR3 ram @ 2133MHz, and an Intel(R) UHD 620 graphics card. 