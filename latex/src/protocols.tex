In this chapter are presented the two main PQKE topic of this dissertation, New Hope, presented in \cite{newhope} by Alkim, Ducas, P{\"o}ppelmann and Schwabe, and Frodo, presented in \cite{frodo} by Bos, Costello, Ducas, Mironov, Naehrig, Nikolaenko, Raghunathan and Stebila with some consideration on their practicality.

\section{New Hope}
In the New Hope paper \cite{newhope}, the authors present some solutions to performance and security issues of the BCNS proposal \cite{BCNS} of an Unauthenticated Post Quantum Key Exchange suitable for use in the TLS cipher suite, deriving the New Hope protocol. \\
As far as performance are concerned, the main improvements are a change in the error distribution, from Gaussian, to a much easier to sample Binomial, the use of a new lattice for error reconciliation, that allows for better error correction, and a drastic drop in the size of the modulus \textit{q}, and finally the use of an encoding for polynomials in the NTT\footnote{More about this in Section \ref{sec:nh:ntt}} domain, which allows to take advantage of the quasi linear product in the NTT domain, while skipping some of the NTT transforms that would usually be necessary.\\
As for security, the authors notice that fixing the parameter \textbf{a} creates an opportunity for an all-for-the-price-of-one attack, and advice to make it ephemeral in order to avoid such risk.\\
Moreover, the authors present a comprehensive security analysis, assessing the security level of the protocol to be comfortably over 128 bit.\\
Let us take the time to go through the proposed changes and examine each of them in detail.

\subsection{Error Distribution}
Previous proposals were considerably burdened by the choice of a Gaussian noise distribution, which is notoriously hard to sample. The authors of New Hope opt for a much easier to sample Binomial distribution $\Psi_k$ of parameter $k=16$. Such distribution is really easy to sample from a stream of uniform i.i.d. random bits, which is commonly available on modern machines. \\
The security of the key exchange is only marginally affected by the choice of this distribution, as we can see in Theorem \ref{thm:bin_f_bound}, for the proof of which we refer to \cite{newhope}.

\begin{theorem}\label{thm:bin_f_bound}
Let $\xi$ be the rounded Gaussian distribution of parameter $\sigma = \sqrt{8}$, let $\mathscr{P}$ be the idealized version of protocol \ref{prot:newhope}, using the distribution $\xi$ instead of $\Psi_{16}$. If an unbounded algorithm succeeds in recovering the pre-hash key $\nu$, given a transcript of an instance of protocol \ref{prot:newhope}, then it would also succeed against $\mathscr{P}$ with probability $q\ge p^{9/8}/26$.
\end{theorem}

\subsection{Reconciliation}
In RLWE applications, usually, one bit of information is encoded in each of the polynomial coefficients. In the context of a key exchange, though, this translates to a message space larger than necessary. This is an opportunity to introduce redundancy in the transmitted message (i.e. the key), trying to increase error tolerance. The authors of New Hope provide a generalization of a bit encoding using two coefficients, presented in \cite{bit_encoding}, which allows to encode a bit in 4 coefficients, further increasing the error tolerance w.r.t to the previous method using two coefficients. It is worth pointing out that the encoding part is not really important as far as the New Hope protocol is concerned. Indeed, the polynomials are always created either as result of operations on other polynomials, or via sampling from some distribution. Decoding, on the other hand, is used to extract the bits of the pre-hash key from the polynomials $\textbf{v}$ and $\textbf{v'}$, and is thus a crucial step of the reconciliation procedure. In order to build this encoding, a polynomial $f(X) \in \mathscr{R} = \mathbb{Z}[X]/(X^n+1)$ has to be split in $n/4$ groups of $4$ coefficients. Then, bits need to be encoded into, and decoded from, groups of four coefficients.

\subsubsection{Polynomial splitting}
The first goal, i.e. the polynomial splitting, can be quite naturally accomplished observing that, given $\mathscr{S} = \mathbb{Z}[X]/(X^4+1)$, we can write $f(X) \in \mathscr{R}$ as $f(X) = f_0 + f_1X + \ldots + f_{1023}X^{1023} = f'_0(X^{256}) + \ldots + f'_{255}(X^{256})X^{255}$, where the $f'_i$ are elements of $\mathscr{S}$, thus identifying $f(X)$ with the vector $(f'_0,\ldots,f'_{255}) \in \mathscr{S}^{256}$. This means that each $f'_i$ is the polynomial of coefficients $f_i,f_{i+256},f_{i+512},f_{i+768}$, which can be identified with a vector in $\mathbb{Z}^4$.

\subsubsection{Bit encoding}
For the encoding, the authors propose to use the lattice $\tilde{D}_4 = \mathbb{Z}^4 \cup \mathbf{g} + \mathbb{Z}^4$, where \textbf{g} is the glue vector $(\frac{1}{2},\frac{1}{2},\frac{1}{2},\frac{1}{2})^t$, such lattice has Voronoi cell $\mathscr{V}$ with relevant vectors $(\pm1,0,0,0),(0,\pm1,0,0),(0,0,\pm1,0),(0,0,0,\pm1)$, said type-A, and $(\pm\frac{1}{2},\pm\frac{1}{2},\pm\frac{1}{2},\pm\frac{1}{2})$, said type-B, respectively 8 and 16 in number.\\
The condition for a correct error recovery, given the cell $\mathscr{V}$, is that given the error vector $e$, then $e\in\mathscr{V}$. This condition can be rewritten as $\langle e,v \rangle \leq \frac{1}{2} \forall v $ relevant vectors. The distinction between the type-A and type-B can be used to cleverly regroup these equations, obtaining $\norm{e \right\rVert_{\infty} \leq \frac{1}{2}$ for type-A vectors, and $\left\lVert e}_1 \leq 1$ for type-B vectors.\\
The last component for the encoding is a base for $\tilde{D}_4$. The authors of \cite{newhope} propose the base $\mathbf{B} = (\mathbf{u}_0,\mathbf{u}_1,\mathbf{u}_2,\mathbf{g})$. Although this might not seem the most natural choice, the presence of the glue vector gives an efficient algorithm for decoding over $\tilde{D}_4/\mathbb{Z}^4$.\\
Indeed, considering that $\mathbf{u}_0,\mathbf{u}_1,\mathbf{u}_2,2\mathbf{g} \in \mathbb{Z}^4$, a vector in $\tilde{D}_4/\mathbb{Z}^4$ is given by the parity of its last coordinate. This means that the encoding of a bit $k\in\mathbb{Z}_2$ can be computed as in Algorithm \ref{alg:nh:encode}, as $k\mathbf{g}$. The decoding is described in Algorithm \ref{alg:nh:decode}, and it can be summed up as looking for the closest vector to the element $\mathbf{x}\in\tilde{D}_4$ to decode, between $\mathbf{0}$ and $\mathbf{g}$. It is easy to see that if $e\in\mathscr{V}$, then $\mathbf{x} + e$ will still be in the same Voronoi cell of $\mathbf{x}$.

\begin{b_algorithm}{$CVP_{\tilde{D}_4}$}
{$\textbf{x} \in \mathbf{R}^4$}
{$\textbf{z} \in \mathbb{Z}^4\text{ }s.t.\text{ }\textbf{x} - \textbf{Bz} \in \mathscr{V}$}
{alg:nh:CVP}
\STATE $\textbf{v}_0 \gets \lfloor\textbf{x}\rceil$
\STATE $\textbf{v}_1 \gets \lfloor\textbf{x}-\textbf{g}\rceil$
\IF{$\|\textbf{x}-\textbf{v}_0\|_1 < 1$}
    \STATE $k \gets 0$
\ELSE
    \STATE $k \gets 1$
\ENDIF
\STATE $(\nu_0,\nu_1,\nu_2,\nu_3)^t \gets \textbf{v}_k$
\RETURN $(\nu_0,\nu_1,\nu_2,k)^t + \nu_3\cdot(-1,-1,-1,2)^t$
\end{b_algorithm}

\begin{b_algorithm}{Encode}
{$k \in \{0,1\}$}
{$\textbf{x} \in \mathbf{R}^4/\mathbb{Z}^4$, the encoding}
{alg:nh:encode}
\RETURN $k\cdot\textbf{g}$
\end{b_algorithm}

\begin{b_algorithm}{Decode}
{$\textbf{x} \in \mathbf{R}^4/\mathbb{Z}^4$}
{$k \in \{0,1\}\text{ }s.t.\text{ }\textbf{x} - k\textbf{g} \in \mathscr{V}+\mathbb{Z}^4$}
{alg:nh:decode}
\STATE $\textbf{v} \gets \mathbf{x} - \lfloor\mathbf{x}\rceil$
\IF{$\|\textbf{v}\|_1\le1$}
    \RETURN $0$
\ELSE
    \RETURN $1$
\ENDIF
\end{b_algorithm}

\subsubsection{Reconciliation}
Finally, all of the ingredients for the reconciliation mechanism are in place. The closest vector any $\mathbf{x}\in\mathbb{R}$ can be computed using the $CVP_{\tilde{D}_4}$ algorithm, described in Algorithm \ref{alg:nh:CVP}, and with this the r-bit reconciliation function \verb|HelpRec| can be defined as 
\begin{equation}
CVP_{\tilde{D}_4}\left(\frac{2^r}{q}(\mathbf{x}+b\mathbf{g})\right)\text{ }\mathrm{mod}\text{ }2^r, where \xleftarrow{\$}U[\{0,1\}].
\end{equation}
Let us call $\mathbf{r}$ the output of the reconciliation function. The final extracted bits can then be computed as 
\begin{equation}
\verb|Decode|\left(\frac{1}{q}\mathbf{x}-\mathbf{Br}\right).
\end{equation}
Applying this algorithm to the polynomial split computed above, the full key can be recovered.\\
The vector $r$, output of the \verb|HelpRec| function, will then be transmitted to the other party, allowing it to apply the final reconciliation to its polynomial split, thus recovering the same key.

%\subsection{Failure rate}
% TODO

\subsection{Generation of the parameter \textbf{a}}\label{sec:nh:a_generation}
The parameter \textbf{a} was made ephemeral, in order to avoid all-for-the-price-of-one attacks and parameter manipulation\footnote{For example, the parameter \textbf{a} can be trapdoored, as described in \cite{RLWE_trapdoor} and \cite{newhope}}. Generating a fresh \textbf{a} for each run of the protocol, opens two problems. The generation of \textbf{a} is computationally somewhat costly, and the generated parameter has to be transmitted to the other party of the key exchange, posing a bandwidth problem.\\
The former issue can be mitigated by caching the parameter \textbf{a} for multiple instances of the protocol, since it has only a marginal effect on the resilience against all-for-the-price-of-one attack. As we can see in Protocol \ref{prot:newhope}, this is quite useful for Alice, which is identified as the Server in a Client-Server connection, and could still be of some use to Bob, which is the Client.\\
The latter is solved by generating the parameter \textbf{a} from a small random seed, using an extendable output cryptographic hash function, SHAKE-128\footnote{This is an extension of the SHA-3 cryptographic hash function \cite{SHA3_FIPS}}, to generate a sequence of pseudo-random bits, which are then parsed into the coefficients of the polynomial \textbf{a}, as described in Algorithm \ref{alg:nh:parse}. The generated \textbf{a} is considered to be in the NTT domain, so there is not need to apply the transform to it. This is a legitimate choice, because the NTT transform preserves uniform noise, so no bias is introduced in the coefficients of \textbf{a} by considering it already in the NTT domain.\\
It is worth to point out that although \verb|Parse| rejects some of the material generated by SHAKE-128, the rejection rate is only $(2^{16}-1-5q)/(2^{16}-1) \approx 0.06$. Since \textbf{a} has $n=1024$ coefficients, and each of them is a 16 bit unsigned integer, SHAKE-128 needs to generate $\approx 2.2$ kbytes of output on average.
\begin{b_algorithm}{Parse function}
{S, a bit sequence, the output of SHAKE-128}
{\textbf{a}, a polynomial, represented as an array of its coefficients}
{alg:nh:parse}
\STATE $i \gets 0$
\STATE $c \gets 0$
\WHILE{$i \le n$}
    \STATE $Xi \gets (uint16)S[16*c .. 16*c+15]$
    \STATE $c++$
    \IF{$Xi \le 5*q$}
        \STATE $\textbf{a}[i] \gets Xi$
        \STATE $i++$
    \ENDIF
\ENDWHILE
\end{b_algorithm}

\subsubsection{Polynomial multiplications using NTT}\label{sec:nh:ntt}
In Section \ref{sec:bg:ntt}, the NTT was mentioned as a method to speed up polynomial products. The cost of this speed gain is the overhead due to all the transforms and inverse transforms needed for each product. In particular, two NTT applications and one inverse NTT application. As mentioned in the previous chapter, the parameter \textbf{a} is already generated in the NTT domain. Moreover, it is possible to keep all of the intermediate results, such as the key shares, in the NTT domain. The only polynomials used in a multiplication that can't be generated already in the NTT domain are the secret keys \textbf{s},\textbf{s'} and the error polynomials \textbf{e},\textbf{e'}. In addition to the four NTT applications necessary for these polynomials, two inverse NTT applications are required to reconstruct the recombined shares from the reconciliation result in the NTT domain. This means that each actor only needs to perform two NTT applications and one inverse NTT application during the entire protocol, instead than for each multiplication.

\subsection{Protocol run}
In Protocol \ref{prot:newhope} is presented a full run of the protocol. Comparing this protocol with the BCNS proposal presented in Protocol \ref{prot:bcns} highlights how similar is the underlying structure of the protocol. Not to take anything away from the many improvements presented in the New Hope paper. This run of the New Hope protocol is for a 128 bit security level, with public parameters $p=12289$, the modulus, and $n=1024$, the degree of the polynomials.\\
\begin{protocol}{New Hope}{Alice}{Bob}\label{prot:newhope}
$seed \xleftarrow{\$}U[\{0,1\}^{256}]$&\\
$\textbf{a}\leftarrow$ \verb|Parse|$($\verb|SHAKE-128|$(seed)))$ &\\
$\textbf{s},\textbf{e}\xleftarrow{\$}\psi^n_{16}$&$\textbf{s'},\textbf{e'},\textbf{e''}\xleftarrow{\$}\psi^n_{16}$\\
$\textbf{b}\leftarrow\textbf{as}+\textbf{e}$&\\
$(seed,\textbf{b})\rightarrow$&$\textbf{a}\leftarrow$ \verb|Parse|$($\verb|SHAKE-128|$(seed)))$\\
&$\textbf{u}\leftarrow\textbf{as'}+\textbf{e'}$\\
&$\textbf{v}\leftarrow\textbf{bs'}+\textbf{e''}$\\
&$\textbf{r}\xleftarrow{\$}$\verb|HelpRec|$(\textbf{v})$\\
$\textbf{v'}\leftarrow\textbf{us}$&$\leftarrow(\textbf{u},\textbf{r})$\\
$\nu\leftarrow$\verb|Rec|$(\textbf{v'},\textbf{r})$&$\nu\leftarrow$\verb|Rec|$(\textbf{v},\textbf{r})$\\
$\mu\leftarrow$\verb|SHA3-256|$(\nu)$&$\mu\leftarrow$\verb|SHA3-256|$(\nu)$\\
\end{protocol}

\section{Going back to LWE}
As mentioned before, RLWE was welcomed as a way to mitigate many of the shortcomings of cryptographic primitives based on the generic LWE problem, namely the memory required to store protocol parameters and private keys, and the bandwidth necessary to transmit said parameters and the public keys, especially when a fresh parameter \textbf{a} is generated for each instance of the protocol.\\
On the other hand, the additional structure in Ideal Lattices, provided by the ring, may enable attacks not viable in the context of Generic Lattices. Some attacks that exploit the ring structure already exist, although they are limited to some parameter choices, and only shave a few bits off the total security provided by the RLWE problem\footnote{A quite comprehensive recap of attacks on the LWE and RLWE problem can be found in \cite{RLWE_attacks}}. Still, the lack of practical attacks exploiting the ring structure in a catastrophic way should not put our minds to rest, as the cryptanalysis on the LWE and RLWE problems is still in its early stages.\\
Only one thing is certain, the RLWE problem is a subcase of the LWE problem, which means that any effective attack against the LWE would also apply to RLWE based cryptographic primitives. The converse is not certain, as any attack on RLWE exploiting the ring structure would fail against LWE based primitives. This is a strong guarantee on the relative security of the two problems, regardless of the available attacks.\\
Nevertheless, the huge performance penalty of LWE primitives has led to an abandonment of this problem, in favor of cheaper RLWE based primitives. Although this led to a sprawl of new protocols, such an abandonment meant that the true potentialities of the LWE problem were not fully explored. This is where the authors of Frodo \cite{frodo} come into play, presenting a viable protocol using LWE primitives and showing that the performance advantages given by the RLWE setting are quite consistent, but not without remedy. 

\section{Frodo}\label{sec:fr}
The authors of Frodo \cite{frodo} take off from the BCNS proposal \cite{BCNS}, using a more general LWE setting, instead of the RLWE used in the original paper. Then, as in the New Hope paper, they propose improvements to the protocol, to make it viable for use in the TLS cipher suite.\\
Since the same security issues pointed out in \cite{newhope} are still valid in the LWE setting, the authors of Frodo are forced to make the parameter \textbf{a} ephemeral, which has an even bigger cost than in the RLWE setting, both in terms of bandwidth and computational cost. As in New Hope, the first issue is solved using a small seed to generate the parameter \textbf{a}, but the size of this parameter in the setting of LWE can still be an issue for more restricted environments, so the authors of Frodo decided to use a generation function that allows for generation of small blocks of \textbf{a}, which can be used and then discarded if caching them in memory is too burdensome. Even after the optimization, the generation process is remarkably costly, taking up to 40\% of the time necessary. Following the same reasoning of Section \ref{sec:nh:a_generation}, caching might be a partial mitigation for this burden.\\
Moreover, the authors present four different easy to sample noise distributions which might be used in place of the rounded Gaussian distribution used in \cite{BCNS}.

\subsection{Error Distribution}\label{sec:pr:distribution}
The authors present four different easy to sample probability distribution that could be used instead of the rounded Gaussian. In order to achieve a reasonable degree of efficiency both in terms of computational cost of sampling, and of entropy required to generate the samples, the authors decide to use inverse sampling, using a pre-computed table for a cumulative density function, CDF from now on, carefully chosen to be as close as possible to a rounded Gaussian distribution\footnote{The authors use the notion of R\`enyi divergence to quantify closeness.}. We refer to \cite{frodo} for the exact tables proposed by the authors of Frodo.\\
Let us examine the procedure for inverse sampling used in Frodo. For instance, take the first distribution\footnote{Called $D_1$ in the original paper.} proposed in \cite{frodo}. This distribution has CDF given by $T=[43,104,124,127]$. In order to inverse sample, generate an uniformly random value $y\in[0,127]$, i.e. seven random bits, and then return the smallest $\bar{x} \in [0,3]\text{ }s.t.\text{ }y\le T[\bar{x}]$. Such $\bar{x}$ can only be positive, while the rounded Gaussian also takes negative values. So, in order to restore the sign, an eighth uniformly random bit is generated and used to choose $s\in\{-1,1\}$, thus generating the final value $x=s\bar{x}$.\\
In general, the construction of a table can be viewed as taking $2^{b-1}$ samples from a rounded Gaussian\footnote{This is just for reference, the CDF are usually hand crafted} and counting the occurrences of the different absolute values. The derived PDF is then converted into a CDF. Since the sign is ignored, the CDF does not resemble a rounded Gaussian anymore, but it is easy to restore the sign, with just an additional random bit, while this procedure allows for a more compact CDF, with only half the values. This procedure has a total requirement of $b$ bits of entropy, and it only costs a constant time table lookup, which runs in $\Theta(\#T)$, and the sign multiplication.\\ 

\subsection{Reconciliation}\label{sec:fr:rec}
The reconciliation mechanism for Frodo is a generalization of the mechanism presented in \cite{peikert_2014}. This generalized mechanism allows packing one or more bit in each approximate agreed element of $\mathbb{Z}_q$\footnote{In this paragraph, $q$ is chosen to be a power of two, but this mechanism can be adapted to work with any modulus.}, similarly to the reconciliation mechanism of New Hope. On the other hand, while in New Hope there was plenty of room to add some redundancy in the agreed polynomial, this is a luxury the authors of Frodo could not afford. On the contrary, for realistic security levels more bits need to be packed in each approximate agreed value. In fact, in order to achieve a security level of $s$ bits, $\bar{n}$, $\bar{m}$ and $B$, the number of bits packed into an agreed value need to be chosen in such a way that $s\ge\bar{m}\bar{n}B$. Increasing $B$ allows to reduce $\bar{m}$ and $\bar{n}$, i.e. the dimension of the LWE matrices, thus decreasing not only the computational cost, but also the bandwidth requirements of the algorithm.\\
Consider the quantity $B$ and $\bar{B}=log_2[q]-B$. Two functions are defined starting from these two quantities: the \textit{rounding} function, as
\begin{align*}
\lfloor \cdot \rceil_{2^B} : \mathbb{Z}_q &\rightarrow [0,2^B-1] \\
v &\mapsto \lfloor 2^{-\bar{B}}v \rceil\text{ mod }2^B
\end{align*}
and the \textit{cross-rounding} function, as
\begin{align*}
\langle \cdot \rangle_{2^B} : \mathbb{Z}_q &\rightarrow \{0,1\}\\
v &\mapsto \lfloor 2^{-\bar{B}+1}v \rfloor\text{ mod }2
\end{align*}
Using these two functions, the \verb|rec| function can be defined as in \cite{peikert_2014}
\begin{align*}
\text{Rec} : \mathbb{Z}_q \times {0,1} &\rightarrow [0,2^B-1]\\
(w,b) &\mapsto \lfloor v \rceil_{2^B}
\end{align*}
where $v$ is the closest vector to $w$ s.t. $\langle v \rangle_{2^B} = b$.\\
In order to conclude that \verb|rec| and the \textit{rounding} function can be used as reconciliation functions in Frodo, it must hold that if $\norm{v-w} < 2^{\bar{B}-2}\Rightarrow\verb|rec|(w,\langle v \rangle)=\lfloor v \rceil_{2^B}$. It is immediate that this is true if $v$ is the closest vector to $w$ with \textit{crossrounding} equal to $\langle v \rangle$, which in turn is ensured by bound on the norm of $v-w$.\\

\subsection{Generation of the parameter \textbf{a}}\label{sec:fr:a_generation}
As mentioned above, a fresh matrix $\textbf{a} \in \mathbb{Z}^{n\times n}_q$ needs to be generated for each protocol instance. The approach followed in Frodo is similar to the one of New Hope. A small uniformly random seed is generated and shared between the parties\footnote{Remember that the parameter \textbf{a} is public}, who can generate the same \textbf{a} using it. Following the same reasoning of \cite{newhope}, the seed is expanded using a function that fits the random oracle model. In particular, the function used for the task is AES128 in ECB mode, using the seed as key and a known plaintext.\\
The procedure starts from a "striped" matrix, $\bar{\textbf{a}}$, $s.t.$ 
\begin{equation*}
\bar{\textbf{a}}[i,j]=
\begin{cases}
i   & if\text{ }j=0\text{ }\mathrm{mod}\text{ }8,    \\
j-1 & if\text{ }j=1\text{ }\mathrm{mod}\text{ }8,    \\
0   & otherwise,                                     \\
\end{cases}
\end{equation*}
which translates in a matrix with the following shape,
\begin{equation*}
\bar{\textbf{a}}=
% Increase maximum columns to fit matrix
\setcounter{MaxMatrixCols}{12}
\begin{bmatrix}
0  & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 8 & 0 & \multirow{4}{*}{$\cdots$}     \\
1  & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 8 & 0 & \\
2  & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 2 & 8 & 0 & \\
3  & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 3 & 8 & 0 & \\
\multicolumn{11}{c}{\vdots}              & \\
n-1& 0 & 0 & 0 & 0 & 0 & 0 & 0 &n-1& 8 & 0 & \cdots \\
\end{bmatrix}.
\end{equation*}
In $\bar{\textbf{a}}$, the elements are represented as 16 bit unsigned integers, memorized in little-endian order\footnote{This allows for a natural implementation on little-endian machines}. Then, the elements of a row are taken in groups of 8 and passed into AES128 in ECB mode, using the seed as key for the cipher, deriving the final $\textbf{a}$.
Notice that the arrays used as plaintext are of the form $[i,8\cdot k,0,\dots,0]\text{ }s.t.\text{ }i\in\{0,\dots,n\},k\in\{0,\dots,n/8\}$, which are all unique, since a pair $(i,k)$ is never repeated. Because of this, and of the random oracle heuristic, the authors justify using this matrix in place of a randomly sampled matrix with uniform distribution.\\
In Algorithm \ref{alg:fr:a_generate}, there is the pseudocode to generate the whole matrix \textbf{a}. It is easy to see that generating the whole matrix is quite burdensome, as this procedure need to instantiate at least one $n\times n$ matrix\footnote{Indeed, the matrix \textbf{a} can overwrite $\bar{\textbf{a}}$, so a second instantiation is not necessary}, or two, if it skips the instantiation of $\bar{\textbf{a}}$ by keeping a pre-generated copy of it. This procedure is particularly unfeasible for restricted environments, where the memory is a precious resource. For instance, using the parameters recommended in \cite{frodo}, such matrix uses a total amount of $752*752*16bit\approx1.1MB$ of memory.\\
All is not lost. This construction of the matrix \textbf{a}, indeed, allows for individual blocks of the matrix to be individually generated quite efficiently, to be then used and discarded when they are not needed anymore. There are two particular ways of generating blocks of the matrix, which are extremely useful for our purpose, i.e. multiplicating the matrix \textbf{a} with other matrices\footnote{Both on the left and on the right. These matrices have lower dimensions, thus being easier to store in memory}. Indeed, the matrix can be generated by rows, as presented in \mbox{Algorithm \ref{alg:fr:a_generate_row}} and by columns, as presented in \mbox{Algorithm \ref{alg:fr:a_generate_columns}}. The generated row, or columns, can be used in the matrix multiplication and then safely discarded, thus slashing the memory consumption for the generation of \textbf{a}, reducing it by a factor of $n/8=94$ for the generation by columns, to $\approx 12KB$, and by a factor of $n=752$, to $\approx 1.5KB$, for the generation by rows\footnote{Assuming the recommended parameters in \cite{frodo} are used}.\\
It is worth pointing out that in the context of TLS the Server might want to cache the parameter \textbf{a} to use it for multiple connections over a set time share, as suggested at the beginning of \ref{sec:fr}. Since Servers usually have a decent amount of memory, they can afford to store the full generated matrix, thus saving about $40\%$ of the computational cost for a protocol instance\footnote{Using a pre-generated \textbf{a}. The cost of generating \textbf{a} on the go is actually lower that generating the full matrix.}. On the other hand, Clients have more limited resources, and almost no benefit from caching, so the generation on the fly is generally preferable for them, both in terms of computational cost and memory usage.

\begin{b_algorithm}{Generate a}
{$seed \in \{0,1\}^{128}$}
{\textbf{a}, an $n\times n$ matrix generated from the seed}
{alg:fr:a_generate}
\STATE \texttt{/* Instantiate $\bar{\textbf{a}}$ */}
\FOR{$i \gets 0$ \TO $n-1$}
\STATE{
    \vspace{-\baselineskip} % Workaround for spacing issue
    \FOR{$j \gets 0$ \TO $n-1$}
    \STATE{
        \vspace{-\baselineskip} % Workaround for spacing issue
        \IF{$j = 0$ mod $8$}
            \STATE$\bar{\textbf{a}}[i,j] \gets i$
        \ELSIF{$j = 1$ mod $8$}
            \STATE$\bar{\textbf{a}}[i,j] \gets j-1$
        \ELSE
            \STATE$\bar{\textbf{a}}[i,j] \gets 0$
        \ENDIF
    }
    \ENDFOR
}
\ENDFOR
\STATE \texttt{/* Generate \textbf{a} */}
\FOR{$i \gets 0$ \TO $n-1$}
\STATE{
    \vspace{-\baselineskip} % Workaround for spacing issue
    \FOR{$j \gets 0$ \TO $n-8 \textbf{ step } 8$}
    \STATE $\textbf{a}[i,j:j+8] \gets AES128(\bar{\textbf{a}}[i,j:j+8], seed)$
    \ENDFOR
}
\ENDFOR
\RETURN \textbf{a}
\end{b_algorithm}

\begin{b_algorithm}{Generate \textbf{a} by rows}
{$seed \in \{0,1\}^{128},i \in \{0,\ldots,n-1\}$, the row index}
{\textbf{a}[i,:], an array of $n$ elements generated from the seed}
{alg:fr:a_generate_row}
\FOR{$j \gets 0$ \TO $n-8 \textbf{ step } 8$}
\STATE $\textbf{a}_i[j:j+8] \gets AES128([i,j,0,0,0,0,0,0], seed)$
\ENDFOR
\RETURN $\textbf{a}_i$
\end{b_algorithm}

\begin{b_algorithm}{Generate \textbf{a} by columns}
{$seed \in \{0,1\}^{128}, j\in \{0,8,\ldots,n-8\}$, the starting column index}
{\textbf{a}[:,j:j+8], an $n\times 8$ matrix generated from the seed}
{alg:fr:a_generate_columns}
\FOR{$i \gets 0$ \TO $n-1$}
\STATE $\textbf{a}_j[i,j:j+8] \gets AES128([i,j,0,0,0,0,0,0], seed)$
\ENDFOR
\RETURN $\textbf{a}_j$
\end{b_algorithm}

\subsection{Protocol run}
In protocol \ref{prot:frodo} is presented a complete run of Frodo, for a security level $s$, with public parameters $(n,q,\chi,\bar{n},\bar{m},B)$. For simplicity, the matrix \textbf{a} is generated with \verb|Gen| as described in Algorithm \ref{alg:fr:a_generate} and subsequently multiplied to create the public terms for the key exchange. It is then  easy to adapt the protocol to generate blocks of \textbf{a} on the fly when executing the matrix multiplication. The Diffie-Hellman like structure inherited from \cite{BCNS} is still quite visible.\\

\begin{protocol}{Frodo}{Alice [Server]}{Bob [Client]}\label{prot:frodo}
$seed \xleftarrow{\$}U[\{0,1\}^s]$&\\
$\textbf{a}\leftarrow$ \verb|Gen|$(seed)$ &\\
$\textbf{s},\textbf{e}\xleftarrow{\$}\chi[\mathbb{Z}^{n\times\bar{n}}_q]$&$\textbf{s'},\textbf{e'}\xleftarrow{\$}\chi[\mathbb{Z}^{\bar{m}\times n_q}]$\\
&$\textbf{e''}\xleftarrow{\$}\chi[\mathbb{Z}^{\bar{m}\times\bar{n}}_q]$\\
$\textbf{b}\leftarrow\textbf{as}+\textbf{e}$&\\
$(seed,\textbf{b})\rightarrow$&$\textbf{a}\leftarrow$ \verb|Gen|$(seed)$\\
&$\textbf{u}\leftarrow\textbf{s'a}+\textbf{e'}$\\
&$\textbf{v}\leftarrow\textbf{s'b}+\textbf{e''}$\\
&$\textbf{r}\xleftarrow{\$}\langle\textbf{v}\rangle_{2^B}$\\
$\textbf{v'}\leftarrow\textbf{us}$&$\leftarrow(\textbf{u},\textbf{r})$\\
$\nu\leftarrow$\verb|Rec|$(\textbf{v'},\textbf{r})$&$\nu\leftarrow\lfloor\textbf{v}\rceil_{2^B}$\\
\end{protocol}
