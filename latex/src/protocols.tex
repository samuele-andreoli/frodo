\section{New Hope}
In the New Hope paper\cite{newhope}, the authors present some solutions to performance and security issues of the BCNS proposal \cite{BCNS} of an Unauthenticated Post Quantum Key Exchange suitable for use in the TLS cipher suite, deriving the New Hope protocol. \\
As far as performance are concerned, the main improvements are a change in the error distribution, from Gaussian, to a much easier to sample Binomial, the use of a new lattice for error reconciliation, that allows for better error correction, and a drastic drop in the size of the modulus \textit{q}, and finally the use of an encoding for polynomials in the NTT\footnote{TODO Reference to the section with the NTT} domain, which allows to take advantage of the quasi linear product in the NTT domain, while skipping some of the NTT transforms that would usually be necessary.\\
As for security, the authors notice that fixing the parameter \textbf{a} creates an opportunity for an all-for-the-price-of-one attack, and advice to make it ephemeral in order to avoid such risk.\\
Moreover, the authors present a comprehensive security analysis, assessing the security level of the protocol to be comfortably over 128 bit.\\
Let's take the time to go through the proposed changes and examine each of them in detail.

\subsection{Error Distribution}
Previous proposals were considerably burdened by the choice of a Gaussian noise distribution, which is notoriously hard to sample. The authors of New Hope opt for a much easier to sample Binomial distribution $\Psi_k$ of parameter $k=16$. Such distribution is really easy to sample from a stream of uniform i.i.d. random bits, which is commonly available on modern machines. \\
The security of the key exchange is only marginally affected by the choice of this distribution, as we can see in Theorem \ref{thm:bin_f_bound}, for the proof of which we refer to \cite{newhope}.

\begin{theorem}\label{thm:bin_f_bound}
Let $\xi$ be the rounded Gaussian distribution of parameter $\sigma = \sqrt{8}$, let $\mathscr{P}$ be the idealized version of protocol \ref{prot:newhope}, using the distribution $\xi$ instead of $\Psi_16$. If an unbounded algorithm succeeds in recovering the pre-hash key $\nu$, given a transcript of an instance of protocol \ref{prot:newhope}, then it would also succeed against $\mathscr{P}$ with probability $q\ge p^{9/8}/26$.
\end{theorem}

\subsection{Generation of \textbf{a}}\label{sec:nh:a_generation}
The parameter \textbf{a} was made ephemeral, in order to avoid all-for-the-price-of-one attacks and parameter manipulation\footnote{For example, the parameter \textbf{a} can be trapdoored, as described in \cite{RLWE_trapdoor} and \cite{newhope}.}. Generating a fresh \textbf{a} for each run of the protocol, opens two problems. The generation of \textbf{a} is computationally somewhat costly, and the generated parameter has to be transmitted to the other party of the key exchange, posing a bandwidth problem.\\
The former issue can be mitigated by caching the parameter \textbf{a} for multiple instances of the protocol, since it has only a marginal effect on the resilience against all-for-the-price-of-one attack. As we can see in Protocol \ref{prot:newhope}, this is quite useful for Alice, which is identified as the Server in a Client-Server connection, and could still be of some use to Bob, which is the Client.\\
The latter is solved by generating the parameter \textbf{a} from a small random seed, using an extendable output cryptographic hash function, SHAKE-128\footnote{This is an extension of the SHA-3 cryptographic hash function \cite{SHA3_FIPS}}, to generate a sequence of pseudo-random bits, which are then parsed into the coefficients of the polynomial \textbf{a}, as described in Algorithm \ref{alg:nh:parse}. The generated \textbf{a} is considered to be in the NTT domain, so there is not need to apply the transform to it. This is a legitimate choice, because the NTT transform preserves uniform noise, so no bias is introduced in the coefficients of \textbf{a} by considering it already in the NTT domain.\\
It's worth to point out that although \verb|Parse| rejects some of the material generated by SHAKE-128, the rejection rate is only $(2^{16}-1-5q)/(2^{16}-1) \approx 0.06$. Since \textbf{a} has $n=1024$ coefficients, and each of them is a 16 bit unsigned integer, SHAKE-128 needs to generate $\approx 2.2$ kbytes of output on average.
\begin{b_algorithm}{Parse function}
{S, a bit sequence, the output of SHAKE-128}
{\textbf{a}, a polynomial, represented as an array of its coefficients}
{alg:nh:parse}
\STATE $i \gets 0$
\STATE $c \gets 0$
\WHILE{$i \le n$}
    \STATE $Xi \gets (uint16)S[16*c .. 16*c+15]$
    \STATE $c++$
    \IF{$Xi \le 5*q$}
        \STATE $\textbf{a}[i] \gets Xi$
        \STATE $i++$
    \ENDIF
\ENDWHILE
\end{b_algorithm}

\subsection{Recovery from errors}
In R-LWE applications, usually, one bit of information is encoded in each of the polynomial coefficients. In the context of a key exchange, though, this translates to a message space larger than necessary. This is an opportunity to introduce redundancy in the transmitted message (i.e. the key), trying to increase error tolerance. The authors of New Hope provide a generalization of a bit encoding using two coefficients, presented in [TODO add citation], which allows to encode a bit in 4 coefficients, further increasing the error tolerance w.r.t to the previous method using two coefficients. It is worth pointing out that the encoding part is not really important as far as the New Hope protocol is concerned. Indeed, the polynomials are always created either as result of operations on other polynomials, or via sampling from some distribution. Decoding, on the other hand, is used to extract the bits of the pre-hash key from the polynomials $\textbf{v}$ and $\textbf{v'}$, and is thus a crucial step of the reconciliation procedure. In order to build this encoding, a polynomial $f(X) \in \mathscr{R} = \mathbf{Z}[X]/(X^n+1)$ has to be split in $n/4$ groups of $4$ coefficients. Then, bits need to be encoded into, and decoded from, groups of four coefficients.

\subsubsection{Polynomial splitting}
The first goal, i.e. the polynomial splitting, can be quite naturally accomplished observing that, given $\mathscr{S} = \mathbf{Z}[X]/(X^4+1)$, we can write $f(X) \in \mathscr{R}$ as $f(X) = f_0 + f_1X + \ldots + f_{1023}X^{1023} = f'_0(X^{256}) + \ldots + f'_{255}(X^{256})X^{255}$, where the $f'_i$ are elements of $\mathscr{S}$, thus identifying $f(X)$ with the vector $(f'_0,\ldots,f'_{255}) \in \mathscr{S}^{256}$. This means that each $f'_i$ is the polynomial of coefficients $f_i,f_{i+256},f_{i+512},f_{i+768}$, which can be identified with a vector in $\mathbf{Z}^4$.

\subsubsection{Bit encoding}
For the encoding, the authors propose to use the lattice $\tilde{D}_4 = \mathbf{Z}^4 \cup \mathbf{g} + \mathbf{Z}^4$, where \textbf{g} is the glue vector $(\frac{1}{2},\frac{1}{2},\frac{1}{2},\frac{1}{2})^t$, such lattice has Voronoi cell $\mathscr{V}$ with relevant vectors $(\pm1,0,0,0),(0,\pm1,0,0),(0,0,\pm1,0),(0,0,0,\pm1)$, said type-A, and $(\pm\frac{1}{2},\pm\frac{1}{2},\pm\frac{1}{2},\pm\frac{1}{2})$, said type-B, respectively 8 and 16 in number.
%% TODO Finish decoding in D4 and Z4/D4

\subsubsection{Failure rate}


\begin{b_algorithm}{$CVP_{\tilde{D}_4}$}
{$\textbf{x} \in \mathbf{R}^4$}
{$\textbf{z} \in \mathbf{Z}^4\text{ }s.t.\text{ }\textbf{x} - \textbf{Bz} \in \mathscr{V}$}
{alg:nh:CVP}
\STATE $\textbf{v}_0 \gets \lfloor\textbf{x}\rceil$
\STATE $\textbf{v}_1 \gets \lfloor\textbf{x}-\textbf{g}\rceil$
\IF{$\|\textbf{x}-\textbf{v}_0\|_1 < 1$}
    \STATE $k \gets 0$
\ELSE
    \STATE $k \gets 1$
\ENDIF
\STATE $(\nu_0,\nu_1,\nu_2,\nu_3)^t \gets \textbf{v}_k$
\RETURN $(\nu_0,\nu_1,\nu_2,k)^t + \nu_3\cdot(-1,-1,-1,2)^t$
\end{b_algorithm}

\begin{b_algorithm}{Encode}
{$k \in \{0,1\}$}
{$\textbf{x} \in \mathbf{R}^4/\mathbf{Z}^4$, the encoding}
{alg:nh:encode}
\RETURN $k\cdot\textbf{g}$
\end{b_algorithm}

\begin{b_algorithm}{Decode}
{$\textbf{x} \in \mathbf{R}^4/\mathbf{Z}^4$}
{$k \in \{0,1\}\text{ }s.t.\text{ }\textbf{x} - k\textbf{g} \in \mathscr{V}+\mathbf{Z}^4$}
{alg:nh:decode}
\STATE $\textbf{v} \gets \mathbf{x} - \lfloor\mathbf{x}\rceil$
\IF{$\|\textbf{v}\|_1\le1$}
    \RETURN $0$
\ELSE
    \RETURN $1$
\ENDIF
\end{b_algorithm}

\subsubsection{NTT and message encoding}
As mentioned above, 

\subsection{Protocol run}
In Protocol \ref{prot:newhope} we can see the end result of the proposed improvements: the New Hope protocol for a 128 bit security level, with public parameters $p=12289$, the modulus, and $n=1024$, the degree of the polynomials.\\
\begin{protocol}{New Hope}{Alice}{Bob}\label{prot:newhope}
$seed \xleftarrow{\$}U[\{0,1\}^{256}]$&\\
$\textbf{a}\leftarrow$ \verb|Parse|$($\verb|SHAKE-128|$(seed)))$ &\\
$\textbf{s},\textbf{e}\xleftarrow{\$}\psi^n_{16}$&$\textbf{s'},\textbf{e'},\textbf{e''}\xleftarrow{\$}\psi^n_{16}$\\
$\textbf{b}\leftarrow\textbf{as}+\textbf{e}$&\\
$(seed,\textbf{b})\rightarrow$&$\textbf{a}\leftarrow$ \verb|Parse|$($\verb|SHAKE-128|$(seed)))$\\
&$\textbf{u}\leftarrow\textbf{as'}+\textbf{e'}$\\
&$\textbf{v}\leftarrow\textbf{bs'}+\textbf{e''}$\\
&$\textbf{r}\xleftarrow{\$}$\verb|HelpRec|$(\textbf{v})$\\
$\textbf{v'}\leftarrow\textbf{us}$&$\leftarrow(\textbf{u},\textbf{r})$\\
$\nu\leftarrow$\verb|Rec|$(\textbf{v'},\textbf{r})$&$\nu\leftarrow$\verb|Rec|$(\textbf{v},\textbf{r})$\\
$\mu\leftarrow$\verb|SHA3-256|$(\nu)$&$\mu\leftarrow$\verb|SHA3-256|$(\nu)$\\
\end{protocol}

\subsection{Security analysis}


\section{Going back to LWE}
%                 Motivo del "ritorno" al LWE


\section{Frodo}\label{sec:fr}
The authors of Frodo \cite{frodo} restart from the BCNS proposal \cite{BCNS}, using a more general LWE setting, instead of the R-LWE used in the original paper. Then, as in the New Hope paper, they propose improvements to the protocol, to make it viable for use in the TLS cipher suite.\\
Since the same security issues pointed out in \cite{newhope} are still valid in the LWE setting, the authors of Frodo are forced to make the parameter \textbf{a} ephemeral, which has an even bigger cost than in the R-LWE setting, both in terms of bandwidth and computational cost. As in New Hope, the first issue is solved using a small seed to generate the parameter \textbf{a}, but the size of this parameter in the setting of LWE can still be an issue for more restricted environments, so the authors of Frodo decided to use a generation function that allows for generation of small blocks of \textbf{a}, which can be used and then discarded if caching them in memory is too burdensome. Even after the optimization, the generation process is remarkably costly, taking up to 40\% of the time necessary. Following the same reasoning of Section \ref{sec:nh:a_generation}, caching might be a partial mitigation for this burden.\\
Moreover, the authors present four different easy to sample noise distributions which might be used in place of the rounded Gaussian distribution used in \cite{BCNS}.

\subsection{Reconciliation}
The reconciliation mechanism for Frodo is a generalization of the mechanism presented in \cite{peikert_2014}. This generalized mechanism allows packing one or more bit in each approximate agreed element of $\mathbf{Z}_q$\footnote{In this paragraph, $q$ is chosen to be a power of two, but this mechanism can be adapted to work with any modulus.}, similarly to the reconciliation mechanism of New Hope. On the other hand, while in New Hope there was plenty of room to add some redundancy in the agreed polynomial, this is a luxury the authors of Frodo couldn't afford. On the contrary, for realistic security levels more bits need to be packed in each approximate agreed value. In fact, in order to achieve a security level of $s$ bits, we need to choose $\bar{n}$, $\bar{m}$ and $B$, the number of bits packed into an agreed value, such that $s\ge\bar{m}\bar{n}B$. Increasing $B$ allows to reduce $\bar{m}$ and $\bar{n}$, i.e. the dimension of the LWE matrices, thus decreasing not only the computational cost, but also the bandwidth requirements of the algorithm.\\
Consider the quantity $B$ and $\bar{B}=log_2[q]-B$. Two functions are defined starting from these two quantities: the \textit{rounding} function, as
\begin{align*}
\lfloor \cdot \rceil_{2^B} : \mathbf{Z}_q &\rightarrow [0,2^B-1] \\
v &\mapsto \lfloor 2^{-\bar{B}}v \rceil\text{ mod }2^B
\end{align*}
and the \textit{cross-rounding} function, as
\begin{align*}
\langle \cdot \rangle_{2^B} : \mathbf{Z}_q &\rightarrow \{0,1\}\\
v &\mapsto \lfloor 2^{-\bar{B}+1}v \rfloor\text{ mod }2
\end{align*}
Using these two functions, the \verb|rec| function can be defined as in \cite{peikert_2014}
\begin{align*}
\text{Rec} : \mathbf{Z}_q \times {0,1} &\rightarrow [0,2^B-1]\\
(w,b) &\mapsto \lfloor v \rceil_{2^B}
\end{align*}
where $v$ is the closest vector to $w$ s.t. $\langle v \rangle_{2^B} = b$.\\
%%                         _                                                           _
%% Claims v u.r => |_ v  | | <v> u.r. and |v-w| < 2^\bar{B}-2 => Rec(w,<v>) = |_ v  |
%% Still undecided if I should put them here or in the security/correctness analysis

\subsection{Error distributions}
As mentioned above, the authors present four different easy to sample probability distribution that could be used instead of the rounded Gaussian. In order to achieve a reasonable degree of efficiency both in terms of computational cost of sampling, and of entropy required to generate the samples, the authors decide to use inverse sampling, using a pre-computed table for a cumulative density function, CDF from now on, carefully chosen to be as close as possible to a rounded Gaussian distribution\footnote{The authors use the notion of R\`enyi divergence to quantify closeness. More details in Section \ref{sec:fr:sec_analysis}}. We refer to \cite{frodo} for the exact tables proposed by the authors of Frodo.\\
Let's examine the procedure for inverse sampling used in Frodo. For instance, take the first distribution\footnote{Called $D_1$ in the original paper.} proposed in \cite{frodo}. This distribution has CDF given by $T\text{ }=\text{ }[43,104,124,127]$. In order to inverse sample, generate an uniformly random value $y\in[0,127]$, i.e. seven random bits, and then return the smallest $\bar{x} \in [0,3]\text{ }s.t.\text{ }y\le T[\bar{x}]$. Such $\bar{x}$ can only be positive, while the rounded Gaussian also takes negative values. So, in order to "restore" the sign, an eight uniformly random bit is generated and used to choose $s\in{-1,1}$, thus generating the final value $x\text{ }=\text{ }s\bar{x}$.\\
In general, the construction of a table can be viewed as taking $2^{b-1}$ samples from a rounded Gaussian\footnote{This is just for reference, the CDF are usually hand crafted} and counting the occurrences of the different absolute values. The derived PDF is then converted into a CDF. Since the sign is ignored, the CDF does not resemble a rounded Gaussian anymore, but it is easy to restore the sign, with just an additional random bit, while this procedure allows for a more compact CDF, with only half the values. This procedure has a total requirement of $b$ bits of entropy, and it only costs a constant time table lookup, which runs in $\Theta(\#T)$, and the sign multiplication.\\ 

\subsection{Generation of \textbf{a}}
As mentioned above, a fresh matrix $\textbf{a} \in \mathbf{Z}^{n\times n}_q$ needs to be generated for each protocol instance. The approach followed in Frodo is similar to the one of New Hope. A small uniformly random seed is generated and shared between the parties\footnote{Remember that the parameter \textbf{a} is public}, who can generate the same \textbf{a} using it. Following the same reasoning of \cite{newhope}, the seed is expanded using a function that fits the random oracle model. In particular, the function used for the task is AES128 in ECB mode, using the seed as key and a known plaintext.\\
The procedure starts from a "striped" matrix, $\bar{\textbf{a}}$, $s.t.$ 
\begin{equation*}
\bar{\textbf{a}}[i,j]=
\begin{cases}
i   & if j=0\text{ mod }8    \\
j-1 & if j=1\text{ mod }8    \\
0   & otherwise              \\
\end{cases}
\end{equation*}
which translates in a matrix with the following shape.
\begin{equation*}
\bar{\textbf{a}}=
% Increase maximum columns to fit matrix
\setcounter{MaxMatrixCols}{12}
\begin{bmatrix}
0  & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 8 & 0 & \multirow{4}{*}{$\cdots$}     \\
1  & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 8 & 0 & \\
2  & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 2 & 8 & 0 & \\
3  & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 3 & 8 & 0 & \\
\multicolumn{11}{c}{$\vdots$}              & \\
n-1& 0 & 0 & 0 & 0 & 0 & 0 & 0 &n-1& 8 & 0 & \cdots \\
\end{bmatrix}
\end{equation*}
In $\bar{\textbf{a}}$, the elements are represented as 16 bit unsigned integers, memorized in little-endian order\footnote{This allows for a natural implementation on little-endian machines}. Then, the elements of a row are taken in groups of 8 and passed into AES128 in ECB mode, using the seed as key for the cipher, deriving the final $\textbf{a}$.
Notice that the arrays used as plaintext are of the form $[i,8\cdot k,0,\dots,0]\text{ }s.t.\text{ }i\in\{0,\dots,n\},k\in\{0,\dots,n/8\}$, which are all unique, since a pair $(i,k)$ is never repeated. Because of this, and of the random oracle heuristic, the authors justify using this matrix in place of a randomly sampled matrix with uniform distribution.\\
In Algorithm \ref{alg:fr:a_generate}, there is the pseudocode to generate the whole matrix \textbf{a}. It is easy to see that generating the whole matrix is quite burdensome, as this procedure need to instantiate at least one $n\times n$ matrix\footnote{Indeed, the matrix \textbf{a} can overwrite $\bar{\textbf{a}}$, so a second instantiation is not necessary}, or two, if it skips the instantiation of $\bar{\textbf{a}}$ by keeping a pre-generated copy of it. This procedure is particularly unfeasible for restricted environments, where the memory is a precious resource. For instance, using the parameters recommended in \cite{frodo}, such matrix uses a total amount of $752*752*16bit\approx1.1MB$ of memory.\\
All is not lost. This construction of the matrix \textbf{a}, indeed, allows for individual blocks of the matrix to be individually generated quite efficiently, to be then used and discarded when they are not needed anymore. There are two particular ways of generating blocks of the matrix, which are extremely useful for our purpose, i.e. multiplicating the matrix \textbf{a} with other matrices\footnote{Both on the left and on the right. These matrices have lower dimensions, thus being easier to store in memory}. Indeed, the matrix can be generated by rows, as we can see in Algorithm \ref{alg:fr:a_generate_row} and by columns, as we can see in Algorithm \ref{alg:fr:a_generate_columns}. The generated row, or columns, can be used in the matrix multiplication and then safely discarded, thus slashing the memory consumption for the generation of \textbf{a}, reducing it by a factor of $n/8=94$ for the generation by columns, to $\approx 12KB$, and by a factor of $n=752$, to $\approx 1.5KB$, for the generation by rows\footnote{Assuming the recommended parameters in \cite{frodo} are used}.\\
It is worth pointing out that in the context of TLS the Server might want to cache the parameter \textbf{a} to use it for multiple connections over a set time share, as suggested at the beginning of \ref{sec:fr}. Since Servers usually have a decent amount of memory, they can afford to store the full generated matrix, thus saving about $40\%$ of the computational cost for a protocol instance\footnote{Using a pre-generated \textbf{a}. The cost of generating \textbf{a} on the go is actually lower that generating the full matrix.}. On the other hand, Clients have more limited resources, and almost no benefit from caching, so the generation on the fly is generally preferable for them, both in terms of computational cost and memory usage.

\begin{b_algorithm}{Generate a}
{$seed \in \{0,1\}^{128}$}
{\textbf{a}, an $n\times n$ matrix generated from the seed}
{alg:fr:a_generate}
\STATE \texttt{/* Instantiate $\bar{\textbf{a}}$ */}
\FOR{$i \gets 0$ \TO $n-1$}
\STATE{
    \vspace{-\baselineskip} % Workaround for spacing issue
    \FOR{$j \gets 0$ \TO $n-1$}
    \STATE{
        \vspace{-\baselineskip} % Workaround for spacing issue
        \IF{$j = 0$ mod $8$}
            \STATE$\bar{\textbf{a}}[i,j] \gets i$
        \ELSIF{$j = 1$ mod $8$}
            \STATE$\bar{\textbf{a}}[i,j] \gets j-1$
        \ELSE
            \STATE$\bar{\textbf{a}}[i,j] \gets 0$
        \ENDIF
    }
    \ENDFOR
}
\ENDFOR
\STATE \texttt{/* Generate \textbf{a} */}
\FOR{$i \gets 0$ \TO $n-1$}
\STATE{
    \vspace{-\baselineskip} % Workaround for spacing issue
    \FOR{$j \gets 0$ \TO $n-8 \textbf{ step } 8$}
    \STATE $\textbf{a}[i,j:j+8] \gets AES128(\bar{\textbf{a}}[i,j:j+8], seed)$
    \ENDFOR
}
\ENDFOR
\RETURN \textbf{a}
\end{b_algorithm}

\begin{b_algorithm}{Generate \textbf{a} by rows}
{$seed \in \{0,1\}^{128},i \in \{0,\ldots,n-1\}$, the row index}
{\textbf{a}[i,:], an array of $n$ elements generated from the seed}
{alg:fr:a_generate_row}
\FOR{$j \gets 0$ \TO $n-8 \textbf{ step } 8$}
\STATE $\textbf{a}_i[j:j+8] \gets AES128([i,j,0,0,0,0,0,0], seed)$
\ENDFOR
\RETURN $\textbf{a}_i$
\end{b_algorithm}

\begin{b_algorithm}{Generate \textbf{a} by columns}
{$seed \in \{0,1\}^{128}, j\in \{0,8,\ldots,n-8\}$, the starting column index}
{\textbf{a}[:,j:j+8], an $n\times 8$ matrix generated from the seed}
{alg:fr:a_generate_columns}
\FOR{$i \gets 0$ \TO $n-1$}
\STATE $\textbf{a}_j[i,j:j+8] \gets AES128([i,j,0,0,0,0,0,0], seed)$
\ENDFOR
\RETURN $\textbf{a}_j$
\end{b_algorithm}

\subsection{Protocol run}
In protocol \ref{prot:frodo} we can see a run of Frodo, for a security level $s$, with public parameters $(n,q,\chi,\bar{n},\bar{m},B)$. For simplicity, the matrix \textbf{a} is generated with \verb|Gen| as described in Algorithm \ref{alg:fr:a_generate} and subsequently multiplied to create the public terms for the key exchange. It is then  easy to adapt the protocol to generate blocks of \textbf{a} on the fly when executing the matrix multiplication.\\

\begin{protocol}{New Hope}{Alice [Server]}{Bob [Client]}\label{prot:frodo}
$seed \xleftarrow{\$}U[\{0,1\}^s]$&\\
$\textbf{a}\leftarrow$ \verb|Gen|$(seed)$ &\\
$\textbf{s},\textbf{e}\xleftarrow{\$}\chi[\mathbf{Z}^{n\times\bar{n}}_q]$&$\textbf{s'},\textbf{e'}\xleftarrow{\$}\chi[\mathbf{Z}^{\bar{m}\times n_q}]$\\
&$\textbf{e''}\xleftarrow{\$}\chi[\mathbf{Z}^{\bar{m}\times\bar{n}}_q]$\\
$\textbf{b}\leftarrow\textbf{as}+\textbf{e}$&\\
$(seed,\textbf{b})\rightarrow$&$\textbf{a}\leftarrow$ \verb|Gen|$(seed)$\\
&$\textbf{u}\leftarrow\textbf{s'a}+\textbf{e'}$\\
&$\textbf{v}\leftarrow\textbf{s'b}+\textbf{e''}$\\
&$\textbf{r}\xleftarrow{\$}\langle\textbf{v}\rangle_{2^B}$\\
$\textbf{v'}\leftarrow\textbf{us}$&$\leftarrow(\textbf{u},\textbf{r})$\\
$\nu\leftarrow$\verb|Rec|$(\textbf{v'},\textbf{r})$&$\nu\leftarrow\lfloor\textbf{v}\rceil_{2^B}$\\
\end{protocol}

\subsection{Security Analysis}\label{sec:fr:sec_analysis}

%                 Protocollo

%                 Problemi risolti e ottimizzazioni
